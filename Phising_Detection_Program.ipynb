{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RRaPA2fK6R9w"
      },
      "outputs": [],
      "source": [
        "# =================\n",
        "# 0. INITIAL SETUP\n",
        "# =================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "from scipy.sparse import hstack\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Global containers to store components between versions\n",
        "version_components = {\n",
        "    'vectorizers': {},\n",
        "    'models': {},\n",
        "    'features': {},\n",
        "    'performance': []\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9bn9ZtEeHHu",
        "outputId": "25c0905f-da57-4e5f-ba90-a10868ef2bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded and preprocessed!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ===============================\n",
        "# 1. DATA LOADING & PREPROCESSING\n",
        "# ===============================\n",
        "def load_and_preprocess():\n",
        "    df = pd.read_csv(\"CEAS_08.csv\")\n",
        "    df['subject'] = df['subject'].fillna('')\n",
        "    df['body'] = df['body'].fillna('')\n",
        "\n",
        "    # Define clean_text INSIDE the function\n",
        "    def clean_text(text):\n",
        "        text = str(text).lower()\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Fix extra spaces\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove special chars\n",
        "        return text\n",
        "\n",
        "\n",
        "    df['clean_body'] = df['body'].apply(clean_text)\n",
        "    df['clean_subject'] = df['subject'].apply(clean_text)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_and_preprocess()\n",
        "print(\"Data loaded and preprocessed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CjMhB16O6U_U"
      },
      "outputs": [],
      "source": [
        "# ======================\n",
        "# VERSION CONTROL SYSTEM\n",
        "# ======================\n",
        "def run_version(version_name, df, use_previous=True):\n",
        "    \"\"\"\n",
        "    Modular version runner\n",
        "    Parameters:\n",
        "        version_name: '1.0', '1.1', '1.3', or '2.0'\n",
        "        use_previous: Whether to reuse components from earlier versions\n",
        "    \"\"\"\n",
        "    if version_name == '1.1':\n",
        "        return version_1_1(df, use_previous)\n",
        "    elif version_name == '1.2':\n",
        "        return version_1_2(df, use_previous)\n",
        "    elif version_name == '2.0':\n",
        "        return version_2_0(df, use_previous)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid version name\")\n",
        "\n",
        "def print_performance():\n",
        "    \"\"\"Display all recorded results\"\"\"\n",
        "    print(\"\\n=== PERFORMANCE COMPARISON ===\")\n",
        "    for result in version_components['performance']:\n",
        "        print(f\"\\nVersion {result['Version']} - {result['Model']}\")\n",
        "        print(f\"Accuracy: {result['Accuracy']:.4f}\")\n",
        "        print(f\"F1 Score: {result['F1 Score']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KWSYHhJXEke6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XAxcAm9g6U6b"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# VERSION 1.1 - SENDER DOMAIN\n",
        "# ===========================\n",
        "def version_1_1(df, use_previous=True):\n",
        "    # Feature engineering\n",
        "    df['sender_domain'] = df['sender'].apply(lambda x: x.split('@')[-1] if pd.notnull(x) else 'missing')\n",
        "    sender_domain_freq = df['sender_domain'].value_counts().to_dict()\n",
        "    df['sender_domain_freq'] = df['sender_domain'].map(sender_domain_freq)\n",
        "\n",
        "    X = df[['clean_body', 'clean_subject', 'sender_domain_freq']]\n",
        "    y = df['label']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Vectorization (reuse if available)\n",
        "    if use_previous and '1.0' in version_components['vectorizers']:\n",
        "        vectorizers = version_components['vectorizers']['1.0']\n",
        "        print(\"Reusing vectorizers from Version 1.0\")\n",
        "    else:\n",
        "        vectorizers = {\n",
        "            'body': TfidfVectorizer().fit(X_train['clean_body']),\n",
        "            'subject': TfidfVectorizer().fit(X_train['clean_subject'])\n",
        "        }\n",
        "\n",
        "    X_train_body = vectorizers['body'].transform(X_train['clean_body'])\n",
        "    X_test_body = vectorizers['body'].transform(X_test['clean_body'])\n",
        "    X_train_subject = vectorizers['subject'].transform(X_train['clean_subject'])\n",
        "    X_test_subject = vectorizers['subject'].transform(X_test['clean_subject'])\n",
        "\n",
        "    # Combine features\n",
        "    X_train_combined = hstack([\n",
        "        X_train_body,\n",
        "        X_train_subject,\n",
        "        X_train['sender_domain_freq'].values.reshape(-1, 1)\n",
        "    ])\n",
        "    X_test_combined = hstack([\n",
        "        X_test_body,\n",
        "        X_test_subject,\n",
        "        X_test['sender_domain_freq'].values.reshape(-1, 1)\n",
        "    ])\n",
        "\n",
        "    # Model training\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train_combined, y_train)\n",
        "    version_components['models']['1.1'] = model\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = model.predict(X_test_combined)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    result = {\n",
        "        'Version': '1.1',\n",
        "        'Model': 'Logistic Regression + Sender Domain',\n",
        "        'Accuracy': accuracy,\n",
        "        'F1 Score': f1\n",
        "    }\n",
        "    version_components['performance'].append(result)\n",
        "\n",
        "    print(f\"\\nVersion 1.1 Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f'{matrix} \\n')\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_sSQlIJK6U39"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# VERSION 1.2 - URL FEATURES\n",
        "# ==========================\n",
        "def version_1_2(df, use_previous=True):\n",
        "    # Feature engineering\n",
        "    df['url_count'] = df['clean_body'].apply(lambda x: len(re.findall(r'http[s]?://', x)))\n",
        "    df['url_presence'] = (df['url_count'] > 0).astype(int)\n",
        "\n",
        "    X = df[['clean_body', 'clean_subject', 'url_count', 'url_presence']]\n",
        "    y = df['label']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Vectorization (reuse if available)\n",
        "    if use_previous and '1.0' in version_components['vectorizers']:\n",
        "        vectorizers = version_components['vectorizers']['1.0']\n",
        "        print(\"Reusing vectorizers from Version 1.0\")\n",
        "    else:\n",
        "        vectorizers = {\n",
        "            'body': TfidfVectorizer().fit(X_train['clean_body']),\n",
        "            'subject': TfidfVectorizer().fit(X_train['clean_subject'])\n",
        "        }\n",
        "\n",
        "    X_train_body = vectorizers['body'].transform(X_train['clean_body'])\n",
        "    X_test_body = vectorizers['body'].transform(X_test['clean_body'])\n",
        "    X_train_subject = vectorizers['subject'].transform(X_train['clean_subject'])\n",
        "    X_test_subject = vectorizers['subject'].transform(X_test['clean_subject'])\n",
        "\n",
        "    # Combine features\n",
        "    X_train_combined = hstack([\n",
        "        X_train_body,\n",
        "        X_train_subject,\n",
        "        X_train[['url_count', 'url_presence']].values\n",
        "    ])\n",
        "    X_test_combined = hstack([\n",
        "        X_test_body,\n",
        "        X_test_subject,\n",
        "        X_test[['url_count', 'url_presence']].values\n",
        "    ])\n",
        "\n",
        "    # Model training\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train_combined, y_train)\n",
        "    version_components['models']['1.2'] = model\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = model.predict(X_test_combined)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    result = {\n",
        "        'Version': '1.2',\n",
        "        'Model': 'Logistic Regression + URL Features',\n",
        "        'Accuracy': accuracy,\n",
        "        'F1 Score': f1\n",
        "    }\n",
        "    version_components['performance'].append(result)\n",
        "\n",
        "    print(f\"\\nVersion 1.2 Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f'{matrix} \\n')\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GkcIrXqy6U1J"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# VERSION 2.0 - RANDOM FOREST\n",
        "# ===========================\n",
        "def version_2_0(df, use_previous=True):\n",
        "    # Combine all features from previous versions\n",
        "    df['sender_domain'] = df['sender'].apply(lambda x: x.split('@')[-1] if pd.notnull(x) else 'missing')\n",
        "    sender_domain_freq = df['sender_domain'].value_counts().to_dict()\n",
        "    df['sender_domain_freq'] = df['sender_domain'].map(sender_domain_freq)\n",
        "    df['url_count'] = df['clean_body'].apply(lambda x: len(re.findall(r'http[s]?://', x)))\n",
        "    df['url_presence'] = (df['url_count'] > 0).astype(int)\n",
        "\n",
        "    X = df[['clean_body', 'clean_subject', 'sender_domain_freq', 'url_count', 'url_presence']]\n",
        "    y = df['label']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Vectorization\n",
        "    if use_previous and '1.0' in version_components['vectorizers']:\n",
        "        vectorizers = version_components['vectorizers']['1.0']\n",
        "        print(\"Reusing vectorizers from Version 1.0\")\n",
        "    else:\n",
        "        vectorizers = {\n",
        "            'body': TfidfVectorizer().fit(X_train['clean_body']),\n",
        "            'subject': TfidfVectorizer().fit(X_train['clean_subject'])\n",
        "        }\n",
        "\n",
        "    X_train_body = vectorizers['body'].transform(X_train['clean_body'])\n",
        "    X_test_body = vectorizers['body'].transform(X_test['clean_body'])\n",
        "    X_train_subject = vectorizers['subject'].transform(X_train['clean_subject'])\n",
        "    X_test_subject = vectorizers['subject'].transform(X_test['clean_subject'])\n",
        "\n",
        "    # Combine features\n",
        "    X_train_combined = hstack([\n",
        "        X_train_body,\n",
        "        X_train_subject,\n",
        "        X_train[['sender_domain_freq', 'url_count', 'url_presence']].values\n",
        "    ])\n",
        "    X_test_combined = hstack([\n",
        "        X_test_body,\n",
        "        X_test_subject,\n",
        "        X_test[['sender_domain_freq', 'url_count', 'url_presence']].values\n",
        "    ])\n",
        "\n",
        "    # Model training\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train_combined, y_train)\n",
        "    version_components['models']['2.0'] = model\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = model.predict(X_test_combined)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    result = {\n",
        "        'Version': '2.0',\n",
        "        'Model': 'Random Forest (All Features)',\n",
        "        'Accuracy': accuracy,\n",
        "        'F1 Score': f1\n",
        "    }\n",
        "    version_components['performance'].append(result)\n",
        "\n",
        "    print(f\"\\nVersion 2.0 Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f'{matrix} \\n')\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr2jT93I6roc",
        "outputId": "e5d3f919-8902-4ce5-b59c-9565f6cb61da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Version 1.1 Results:\n",
            "Accuracy: 0.9941\n",
            "F1 Score: 0.9947\n",
            "[[3466   24]\n",
            " [  22 4319]] \n",
            "\n",
            "\n",
            "Version 1.2 Results:\n",
            "Accuracy: 0.9945\n",
            "F1 Score: 0.9950\n",
            "[[3468   22]\n",
            " [  21 4320]] \n",
            "\n",
            "\n",
            "Version 2.0 Results:\n",
            "Accuracy: 0.9920\n",
            "F1 Score: 0.9927\n",
            "[[3460   30]\n",
            " [  33 4308]] \n",
            "\n",
            "\n",
            "=== PERFORMANCE COMPARISON ===\n",
            "\n",
            "Version 1.1 - Logistic Regression + Sender Domain\n",
            "Accuracy: 0.9941\n",
            "F1 Score: 0.9947\n",
            "\n",
            "Version 1.2 - Logistic Regression + URL Features\n",
            "Accuracy: 0.9945\n",
            "F1 Score: 0.9950\n",
            "\n",
            "Version 2.0 - Random Forest (All Features)\n",
            "Accuracy: 0.9920\n",
            "F1 Score: 0.9927\n"
          ]
        }
      ],
      "source": [
        "# =================\n",
        "# EXECUTION CONTROL\n",
        "# =================\n",
        "\n",
        "run_version('1.1', df)\n",
        "run_version('1.2', df)\n",
        "run_version('2.0', df)\n",
        "\n",
        "print_performance()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjOlVDQdTn90",
        "outputId": "bba6b42b-7ba3-474c-ea0c-42e1f3992e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Accuracy ===\n",
            "0.661345932831056\n",
            "\n",
            "=== Confusion Matrix ===\n",
            "[[1975 1515]\n",
            " [1137 3204]]\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.57      0.60      3490\n",
            "           1       0.68      0.74      0.71      4341\n",
            "\n",
            "    accuracy                           0.66      7831\n",
            "   macro avg       0.66      0.65      0.65      7831\n",
            "weighted avg       0.66      0.66      0.66      7831\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# VERSION 1.0 - BASELINE\n",
        "# ======================\n",
        "\n",
        "df = pd.read_csv(\"CEAS_08.csv\")\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"link\", text)\n",
        "    text = re.sub(r'[^\\w\\s./-]', '', text)\n",
        "    return text\n",
        "\n",
        "df[\"clean_body\"] = df[\"body\"].apply(clean_text)\n",
        "\n",
        "\n",
        "\n",
        "df[\"email_length\"] = df[\"body\"].str.len()\n",
        "\n",
        "# B. URL Features\n",
        "df[\"has_urls\"] = (df[\"urls\"] > 0).astype(int)\n",
        "\n",
        "\n",
        "df[\"body_cap_ratio\"] = df[\"body\"].str.findall(r'[A-Z]').str.len() / df[\"email_length\"]\n",
        "df[\"subject_cap_ratio\"] = df[\"subject\"].str.findall(r'[A-Z]').str.len() / df[\"subject\"].str.len()\n",
        "\n",
        "\n",
        "revised_words = [\"click\", \"urgent\", \"bank\", \"immediately\"]\n",
        "for word in revised_words:\n",
        "    df[f\"has_{word}\"] = df[\"clean_body\"].str.contains(word).astype(int)\n",
        "df[\"suspicious_score\"] = df[[f\"has_{w}\" for w in revised_words]].sum(axis=1)\n",
        "\n",
        "\n",
        "df.drop(columns=[\"urls\", \"special_chars\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "final_features = [\n",
        "    \"email_length\",\n",
        "    \"body_cap_ratio\",\n",
        "    \"subject_cap_ratio\",\n",
        "    \"suspicious_score\",\n",
        "    \"has_urls\"\n",
        "]\n",
        "\n",
        "\n",
        "# Fill any NaNs caused by division or missing data\n",
        "df[\"body_cap_ratio\"].fillna(0, inplace=True)\n",
        "df[\"subject_cap_ratio\"].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "X = df[final_features]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Accuracy ===\")\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"\\n=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\n=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
